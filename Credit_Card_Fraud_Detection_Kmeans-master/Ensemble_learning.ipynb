{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Jaykumar-coder/Kmeans/blob/master/Ensemble_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gPAFABC1jTHU"
   },
   "source": [
    "Max Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3RGAbQSSh-F7"
   },
   "outputs": [],
   "source": [
    "model1 = tree.DecisionTreeClassifier()\n",
    "model2 = KNeighborsClassifier()\n",
    "model3= LogisticRegression()\n",
    "\n",
    "model1.fit(x_train,y_train)\n",
    "model2.fit(x_train,y_train)\n",
    "model3.fit(x_train,y_train)\n",
    "\n",
    "pred1=model1.predict(x_test)\n",
    "pred2=model2.predict(x_test)\n",
    "pred3=model3.predict(x_test)\n",
    "\n",
    "final_pred = np.array([])\n",
    "for i in range(0,len(x_test)):\n",
    "    final_pred = np.append(final_pred, mode([pred1[i], pred2[i], pred3[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tOpUDo1ijfKJ"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "model1 = LogisticRegression(random_state=1)\n",
    "model2 = tree.DecisionTreeClassifier(random_state=1)\n",
    "model = VotingClassifier(estimators=[('lr', model1), ('dt', model2)], voting='hard')\n",
    "model.fit(x_train,y_train)\n",
    "model.score(x_test,y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U6eljJVEkQKw"
   },
   "source": [
    "Averaging and weighted averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QCQDeKiyjf5r"
   },
   "outputs": [],
   "source": [
    "model1 = tree.DecisionTreeClassifier()\n",
    "model2 = KNeighborsClassifier()\n",
    "model3= LogisticRegression()\n",
    "\n",
    "model1.fit(x_train,y_train)\n",
    "model2.fit(x_train,y_train)\n",
    "model3.fit(x_train,y_train)\n",
    "\n",
    "pred1=model1.predict_proba(x_test)\n",
    "pred2=model2.predict_proba(x_test)\n",
    "pred3=model3.predict_proba(x_test)\n",
    "\n",
    "finalpred=(pred1*0.3+pred2*0.3+pred3*0.4)\n",
    "\n",
    "finalpred=(pred1+pred2+pred3)/3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1l0TKtX9mr7X"
   },
   "source": [
    "Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rbIkZpxuncbj"
   },
   "source": [
    "We first define a function to make predictions on n-folds of train and test dataset. This function returns the predictions for train and test for each model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K93izAf1kVti"
   },
   "outputs": [],
   "source": [
    "def Stacking(model,train,y,test,n_fold):\n",
    "   folds=StratifiedKFold(n_splits=n_fold,random_state=1)\n",
    "   test_pred=np.empty((test.shape[0],1),float)\n",
    "   train_pred=np.empty((0,1),float)\n",
    "   for train_indices,val_indices in folds.split(train,y.values):\n",
    "      x_train,x_val=train.iloc[train_indices],train.iloc[val_indices]\n",
    "      y_train,y_val=y.iloc[train_indices],y.iloc[val_indices]\n",
    "\n",
    "      model.fit(X=x_train,y=y_train)\n",
    "      train_pred=np.append(train_pred,model.predict(x_val))\n",
    "      test_pred=np.append(test_pred,model.predict(test))\n",
    "    return test_pred.reshape(-1,1),train_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IS9FUhYWnnoC"
   },
   "source": [
    "Now we’ll create two base models – decision tree and knn.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vTQ6M0bwnkEx"
   },
   "outputs": [],
   "source": [
    "model1 = tree.DecisionTreeClassifier(random_state=1)\n",
    "\n",
    "test_pred1 ,train_pred1=Stacking(model=model1,n_fold=10, train=x_train,test=x_test,y=y_train)\n",
    "\n",
    "train_pred1=pd.DataFrame(train_pred1)\n",
    "test_pred1=pd.DataFrame(test_pred1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uHS2F9-DnkZ-"
   },
   "outputs": [],
   "source": [
    "model2 = KNeighborsClassifier()\n",
    "\n",
    "test_pred2 ,train_pred2=Stacking(model=model2,n_fold=10,train=x_train,test=x_test,y=y_train)\n",
    "\n",
    "train_pred2=pd.DataFrame(train_pred2)\n",
    "test_pred2=pd.DataFrame(test_pred2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "du0SwFgin7_q"
   },
   "source": [
    "Create a third model, logistic regression, on the predictions of the decision tree and knn models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VhlTEdnqn4Lp"
   },
   "outputs": [],
   "source": [
    "df = pd.concat([train_pred1, train_pred2], axis=1)\n",
    "df_test = pd.concat([test_pred1, test_pred2], axis=1)\n",
    "\n",
    "model = LogisticRegression(random_state=1)\n",
    "model.fit(df,y_train)\n",
    "model.score(df_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NpMaj6PurJ2U"
   },
   "source": [
    "Algorithms based on Bagging and Boosting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oujeTtuSs6Fu"
   },
   "source": [
    "Bagging meta-estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QdRJJ_B5rT8L"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn import tree\n",
    "model = BaggingClassifier(tree.DecisionTreeClassifier(random_state=1))\n",
    "model.fit(x_train, y_train)\n",
    "model.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R6O4iDBxteok"
   },
   "source": [
    "Ada Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yoTSwQdetnHl"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "model = AdaBoostClassifier(random_state=1)\n",
    "model.fit(x_train, y_train)\n",
    "model.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B_gMwbhgu4ux"
   },
   "source": [
    "Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xrXlPkfjtql9"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "model= GradientBoostingClassifier(learning_rate=0.01,random_state=1)\n",
    "model.fit(x_train, y_train)\n",
    "model.score(x_test,y_test)\n",
    "\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "model= GradientBoostingRegressor()\n",
    "model.fit(x_train, y_train)\n",
    "model.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a3545BSGv-IX"
   },
   "source": [
    "XG Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DrdrcR54wYFX"
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "model=xgb.XGBClassifier(random_state=1,learning_rate=0.01)\n",
    "model.fit(x_train, y_train)\n",
    "model.score(x_test,y_test)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO/IUw1wmUPn7T2xwrCgLg5",
   "include_colab_link": true,
   "name": "Ensemble learning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
